# [NeurIPS 2025 Oral] OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model

This is the offical code repo for **NeurIPS 2025 Oral** paper **OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model**

[[paper]](https://arxiv.org/abs/2505.18947) [[project page]](http://openhoi.github.io/)

<div align="center">
    <img src="pipeline.png" height=500>
</div>



**We will release our code as soon as possible**

Any Question, feel free to contact zhangzhh2024@shanghaitech.edu.cn

# Acknowledgement
Thanks for the excellent work [ShapeLLM](https://github.com/qizekun/ShapeLLM/),[Text2HOI](https://github.com/JunukCha/Text2HOI),[SeqAfford](https://github.com/hq-King/SeqAfford),[GazeHOI](https://github.com/takiee/GazeHOI-toolkit)